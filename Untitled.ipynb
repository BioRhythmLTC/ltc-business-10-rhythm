{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b954804a-d546-4412-b5cc-c82215c9cb10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n",
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "# В ячейке Jupyter поставь с ! перед командой\n",
    "!pip install -q transformers datasets seqeval torch torchvision torchaudio fastapi uvicorn python-multipart\n",
    "# Опционально (если хочешь ONNX Runtime для ускорения inference на CPU)\n",
    "!pip install -q onnxruntime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47578c3e-25bd-45ff-a8be-b3d692572215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363f97f-6b18-49c1-8b62-31ae9d7eb29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./x5_ner_env/lib/python3.9/site-packages (4.56.2)\n",
      "Requirement already satisfied: filelock in ./x5_ner_env/lib/python3.9/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./x5_ner_env/lib/python3.9/site-packages (from transformers) (0.35.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./x5_ner_env/lib/python3.9/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./x5_ner_env/lib/python3.9/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./x5_ner_env/lib/python3.9/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./x5_ner_env/lib/python3.9/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in ./x5_ner_env/lib/python3.9/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./x5_ner_env/lib/python3.9/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./x5_ner_env/lib/python3.9/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./x5_ner_env/lib/python3.9/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./x5_ner_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./x5_ner_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./x5_ner_env/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./x5_ner_env/lib/python3.9/site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./x5_ner_env/lib/python3.9/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./x5_ner_env/lib/python3.9/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./x5_ner_env/lib/python3.9/site-packages (from requests->transformers) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ce719b-5d57-4356-8f9e-efa29c1e6bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in ./x5_ner_env/lib/python3.9/site-packages (1.10.1)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in ./x5_ner_env/lib/python3.9/site-packages (from accelerate) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./x5_ner_env/lib/python3.9/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in ./x5_ner_env/lib/python3.9/site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in ./x5_ner_env/lib/python3.9/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in ./x5_ner_env/lib/python3.9/site-packages (from accelerate) (2.8.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in ./x5_ner_env/lib/python3.9/site-packages (from accelerate) (0.35.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./x5_ner_env/lib/python3.9/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in ./x5_ner_env/lib/python3.9/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./x5_ner_env/lib/python3.9/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.9.0)\n",
      "Requirement already satisfied: requests in ./x5_ner_env/lib/python3.9/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./x5_ner_env/lib/python3.9/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./x5_ner_env/lib/python3.9/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./x5_ner_env/lib/python3.9/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.10)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./x5_ner_env/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx in ./x5_ner_env/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./x5_ner_env/lib/python3.9/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./x5_ner_env/lib/python3.9/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./x5_ner_env/lib/python3.9/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./x5_ner_env/lib/python3.9/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./x5_ner_env/lib/python3.9/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./x5_ner_env/lib/python3.9/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./x5_ner_env/lib/python3.9/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b82e8c79-dc87-4464-8bd1-09815e981506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: импорты и константы\n",
    "import ast\n",
    "import re\n",
    "import json\n",
    "from typing import List, Tuple, Dict, Any\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "\n",
    "# Название модели (можешь менять)\n",
    "MODEL_NAME = \"DeepPavlov/rubert-base-cased\"\n",
    "\n",
    "# Метки (как в задании — BIO по 4 типам)\n",
    "LABELS = [\n",
    "    \"O\",\n",
    "    \"B-TYPE\",\"I-TYPE\",\n",
    "    \"B-BRAND\",\"I-BRAND\",\n",
    "    \"B-VOLUME\",\"I-VOLUME\",\n",
    "    \"B-PERCENT\",\"I-PERCENT\",\n",
    "]\n",
    "label2id = {lbl: idx for idx, lbl in enumerate(LABELS)}\n",
    "id2label = {idx: lbl for lbl, idx in label2id.items()}\n",
    "\n",
    "# Entity types для финальной метрики\n",
    "ENTITY_TYPES = [\"TYPE\",\"BRAND\",\"VOLUME\",\"PERCENT\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7539ce5-6c7c-4e25-ae57-4547d5777b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 7, 'B-TYPE')]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: парсер разметки\n",
    "def parse_annotation_str(s: str) -> List[Tuple[int,int,str]]:\n",
    "    \"\"\"\n",
    "    Разбирает строку вида \"[(0, 7, 'B-TYPE'), (9, 13, 'B-VOLUME')]\" в список кортежей.\n",
    "    Возвращает [] если пусто или недоступно.\n",
    "    \"\"\"\n",
    "    if not s or str(s).strip() in (\"\", \"[]\", \"None\"):\n",
    "        return []\n",
    "    try:\n",
    "        parsed = ast.literal_eval(s)\n",
    "        out = []\n",
    "        for item in parsed:\n",
    "            if len(item) < 3:\n",
    "                continue\n",
    "            start = int(item[0])\n",
    "            end = int(item[1])\n",
    "            tag = str(item[2])\n",
    "            out.append((start, end, tag))\n",
    "        return out\n",
    "    except Exception as e:\n",
    "        # если парсинг не удался — вернем пустой список, но можно логировать\n",
    "        print(\"Warning: can't parse annotation:\", s, \" -> \", e)\n",
    "        return []\n",
    "\n",
    "# Тестовый пример\n",
    "print(parse_annotation_str(\"[(0, 7, 'B-TYPE')]\"))\n",
    "print(parse_annotation_str(\"[]\"))\n",
    "print(parse_annotation_str(\"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae8a45a0-7c50-40c8-a5be-3a9cd2032b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa</td>\n",
       "      <td>[(0, 2, 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aala</td>\n",
       "      <td>[(0, 4, 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aarcca</td>\n",
       "      <td>[(0, 6, 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abon</td>\n",
       "      <td>[(0, 4, 'O')]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abso</td>\n",
       "      <td>[(0, 4, 'B-BRAND')]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample           annotation\n",
       "0      aa        [(0, 2, 'O')]\n",
       "1    aala        [(0, 4, 'O')]\n",
       "2  aarcca        [(0, 6, 'O')]\n",
       "3    abon        [(0, 4, 'O')]\n",
       "4    abso  [(0, 4, 'B-BRAND')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 3: загрузка файла и ручная проверка\n",
    "df = pd.read_csv(\"/Users/marina/Documents/projects/X5/Датасет 2/train.csv\", sep=\";\")  # если csv большой, можно использовать chunksize\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b1d3446-b02d-4887-a3d9-959edc21394b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: функция токенизации + выравнивания label'ов\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "# Cell X: безопасная токенизация и выравнивание меток\n",
    "from typing import List, Tuple\n",
    "\n",
    "def tokenize_and_align_labels_safe(\n",
    "    examples: List[str],\n",
    "    annotations: List[List[Tuple[int,int,str]]],\n",
    "    max_length: int = 128\n",
    "):\n",
    "    \"\"\"\n",
    "    Преобразует список текстов и их аннотаций в формат, пригодный для обучения NER.\n",
    "    Проверяет разметку и безопасно обрабатывает 'O' или некорректные теги.\n",
    "    \n",
    "    Args:\n",
    "        examples: список строк (текстов)\n",
    "        annotations: список списков кортежей (start, end, tag) для каждой строки\n",
    "        max_length: максимальная длина токенизированного текста\n",
    "    \n",
    "    Returns:\n",
    "        dict с ключами: input_ids, attention_mask, labels, offset_mapping\n",
    "    \"\"\"\n",
    "    enc = tokenizer(\n",
    "        examples,\n",
    "        truncation=True,\n",
    "        padding=False,   # паддинг будем делать позже в DataCollator\n",
    "        max_length=max_length,\n",
    "        return_offsets_mapping=True,\n",
    "        return_attention_mask=True\n",
    "    )\n",
    "\n",
    "    all_labels = []\n",
    "\n",
    "    for i, offsets in enumerate(enc[\"offset_mapping\"]):\n",
    "        spans = annotations[i]  # разметка для текущего текста\n",
    "        token_labels = []\n",
    "\n",
    "        for tidx, (t_s, t_e) in enumerate(offsets):\n",
    "            # Специальные токены ([CLS], [SEP] и т.д.)\n",
    "            if t_s == t_e:\n",
    "                token_labels.append(-100)\n",
    "                continue\n",
    "\n",
    "            # Найдём пересечение токена с сущностью\n",
    "            assigned_label = \"O\"\n",
    "            found_span = None\n",
    "            for ent_s, ent_e, ent_tag in spans:\n",
    "                if t_e <= ent_s or t_s >= ent_e:\n",
    "                    continue  # токен левее или правее сущности\n",
    "                found_span = (ent_s, ent_e, ent_tag)\n",
    "                break\n",
    "\n",
    "            if found_span is None:\n",
    "                token_labels.append(label2id[\"O\"])\n",
    "            else:\n",
    "                ent_s, ent_e, ent_tag = found_span\n",
    "\n",
    "                # безопасная проверка: есть ли дефис\n",
    "                if \"-\" in ent_tag:\n",
    "                    ent_type = ent_tag.split(\"-\",1)[1]  # TYPE, BRAND, ...\n",
    "                    if t_s <= ent_s < t_e:\n",
    "                        lbl = f\"B-{ent_type}\"\n",
    "                    else:\n",
    "                        lbl = f\"I-{ent_type}\"\n",
    "                    token_labels.append(label2id.get(lbl, label2id[\"O\"]))\n",
    "                else:\n",
    "                    # случай O или некорректного тега\n",
    "                    token_labels.append(label2id[\"O\"])\n",
    "\n",
    "        all_labels.append(token_labels)\n",
    "\n",
    "    # сохраняем и возвращаем offsets для отладки\n",
    "    enc[\"labels\"] = all_labels\n",
    "    return enc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4d8fc30-24b0-4453-9f85-384c3ca5334d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train examples: 24525\n",
      "Validation examples: 2726\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Подготовим списки текстов и аннотаций\n",
    "texts = df[\"sample\"].astype(str).tolist()           # у тебя колонка называется 'sample'\n",
    "annotations_parsed = [parse_annotation_str(s) for s in df[\"annotation\"].tolist()]\n",
    "\n",
    "# Разделение на train и validation\n",
    "train_texts, val_texts, train_ann, val_ann = train_test_split(\n",
    "    texts, annotations_parsed, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Train examples:\", len(train_texts))\n",
    "print(\"Validation examples:\", len(val_texts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ea4b7b9-bbd3-47a4-8926-6ebb3b459f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: split train/val and prepare HF Dataset\n",
    "train_enc = tokenize_and_align_labels_safe(train_texts, train_ann, max_length=128)\n",
    "val_enc = tokenize_and_align_labels_safe(val_texts, val_ann, max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9300f81-82ee-4e67-b80a-aea8e0961b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(LABELS),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ea70206-abe5-4560-a2b6-63e2c7fd2500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bk/4wc9ztq51bxfsjvx3zkz1hmc0000gn/T/ipykernel_53527/3299289332.py:62: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "/Users/marina/Documents/projects/X5/x5_ner_env/lib/python3.9/site-packages/torch/utils/data/dataloader.py:684: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3066' max='3066' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3066/3066 16:15, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.649700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.435100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.381000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.350800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.344000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.374200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.285200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.342000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.295900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.325700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.289000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.302300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.247800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.295200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.326200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.217200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.236700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.269600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.232300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.253700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.230900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.225900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.216400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.252200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.226300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marina/Documents/projects/X5/x5_ner_env/lib/python3.9/site-packages/transformers/trainer.py:4360: UserWarning: mtime may not be reliable on this filesystem, falling back to numerical ordering\n",
      "  warnings.warn(\"mtime may not be reliable on this filesystem, falling back to numerical ordering\")\n",
      "/Users/marina/Documents/projects/X5/x5_ner_env/lib/python3.9/site-packages/transformers/trainer.py:4360: UserWarning: mtime may not be reliable on this filesystem, falling back to numerical ordering\n",
      "  warnings.warn(\"mtime may not be reliable on this filesystem, falling back to numerical ordering\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3066, training_loss=0.2968198604546414, metrics={'train_runtime': 982.786, 'train_samples_per_second': 24.955, 'train_steps_per_second': 3.12, 'total_flos': 91732194258084.0, 'train_loss': 0.2968198604546414, 'epoch': 1.0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 7: TrainingArguments и Trainer (baseline)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"hf_out\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2\n",
    ")\n",
    "\n",
    "\n",
    "# Для промежуточной метрики используем seqeval (token-level).\n",
    "import evaluate\n",
    "\n",
    "seq_metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_token_metrics(pred):\n",
    "    \"\"\"\n",
    "    Функция считает token-level metrics через seqeval.\n",
    "    Это полезно для мониторинга, но финальная проверка будет entity-level.\n",
    "    \"\"\"\n",
    "    preds = np.argmax(pred.predictions, axis=2)\n",
    "    label_list = LABELS\n",
    "    # Преобразуем, пропуская метки с -100\n",
    "    true_nested = []\n",
    "    pred_nested = []\n",
    "    for i, lab in enumerate(pred.label_ids):\n",
    "        true_seq = []\n",
    "        pred_seq = []\n",
    "        for j, label_id in enumerate(lab):\n",
    "            if label_id == -100:\n",
    "                continue\n",
    "            true_seq.append(label_list[label_id])\n",
    "            pred_seq.append(label_list[preds[i][j]])\n",
    "        true_nested.append(true_seq)\n",
    "        pred_nested.append(pred_seq)\n",
    "    results = seq_metric.compute(predictions=pred_nested, references=true_nested)\n",
    "    return {\n",
    "        \"eval_precision\": results.get(\"overall_precision\", 0.0),\n",
    "        \"eval_recall\": results.get(\"overall_recall\", 0.0),\n",
    "        \"eval_f1\": results.get(\"overall_f1\", 0.0)\n",
    "    }\n",
    "from datasets import Dataset\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": train_enc[\"input_ids\"],\n",
    "    \"attention_mask\": train_enc[\"attention_mask\"],\n",
    "    \"labels\": train_enc[\"labels\"],\n",
    "    \"offset_mapping\": train_enc[\"offset_mapping\"],  # для отладки, можно убрать\n",
    "    \"text\": train_texts\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": val_enc[\"input_ids\"],\n",
    "    \"attention_mask\": val_enc[\"attention_mask\"],\n",
    "    \"labels\": val_enc[\"labels\"],\n",
    "    \"offset_mapping\": val_enc[\"offset_mapping\"],\n",
    "    \"text\": val_texts\n",
    "})\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_token_metrics\n",
    ")\n",
    "\n",
    "# Запуск тренировки (выполняй, когда готов)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8481402c-e895-4f18-880c-e3ec9b89086d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_spans(pred_label_ids: List[int], offsets: List[Tuple[int,int]]) -> List[Tuple[int,int,str]]:\n",
    "    \"\"\"\n",
    "    pred_label_ids: список id меток для токенов (без -100)\n",
    "    offsets: список (start_char, end_char) для токенов\n",
    "    Возвращает список (start_char, end_char, 'B-TYPE') spans\n",
    "    \"\"\"\n",
    "    spans = []\n",
    "    cur = None  # [start_char, end_char, typ]\n",
    "    for lid, (t_s, t_e) in zip(pred_label_ids, offsets):\n",
    "        if t_s == t_e:\n",
    "            continue\n",
    "        label = id2label[int(lid)]\n",
    "        if label == \"O\":\n",
    "            if cur is not None:\n",
    "                spans.append((cur[0], cur[1], f\"B-{cur[2]}\"))\n",
    "                cur = None\n",
    "        else:\n",
    "            pref, typ = label.split(\"-\", 1)\n",
    "            if pref == \"B\":\n",
    "                if cur is not None:\n",
    "                    spans.append((cur[0], cur[1], f\"B-{cur[2]}\"))\n",
    "                cur = [t_s, t_e, typ]\n",
    "            else:  # I-\n",
    "                if cur is None:\n",
    "                    # некорректный I без B — начнём новую сущность\n",
    "                    cur = [t_s, t_e, typ]\n",
    "                else:\n",
    "                    # расширяем текущую сущность вправо\n",
    "                    cur[1] = t_e\n",
    "    if cur is not None:\n",
    "        spans.append((cur[0], cur[1], f\"B-{cur[2]}\"))\n",
    "    return spans\n",
    "\n",
    "def compute_entity_macro_f1(y_true_spans_list: List[List[Tuple[int,int,str]]],\n",
    "                            y_pred_spans_list: List[List[Tuple[int,int,str]]]) -> Tuple[float, Dict[str,float]]:\n",
    "    \"\"\"\n",
    "    y_true_spans_list и y_pred_spans_list: списки списков span-ов для каждого примера.\n",
    "    Возвращает (macro_f1, per_type_f1_dict).\n",
    "    \"\"\"\n",
    "    stats = {t: {\"TP\":0,\"FP\":0,\"FN\":0} for t in ENTITY_TYPES}\n",
    "    for true_spans, pred_spans in zip(y_true_spans_list, y_pred_spans_list):\n",
    "        true_by_type = defaultdict(set)\n",
    "        pred_by_type = defaultdict(set)\n",
    "        for s,e,tag in true_spans:\n",
    "            typ = tag.split(\"-\",1)[1]\n",
    "            true_by_type[typ].add((s,e))\n",
    "        for s,e,tag in pred_spans:\n",
    "            typ = tag.split(\"-\",1)[1]\n",
    "            pred_by_type[typ].add((s,e))\n",
    "        for t in ENTITY_TYPES:\n",
    "            tp = len(true_by_type[t] & pred_by_type[t])\n",
    "            fp = len(pred_by_type[t] - true_by_type[t])\n",
    "            fn = len(true_by_type[t] - pred_by_type[t])\n",
    "            stats[t][\"TP\"] += tp\n",
    "            stats[t][\"FP\"] += fp\n",
    "            stats[t][\"FN\"] += fn\n",
    "\n",
    "    f1s = {}\n",
    "    for t in ENTITY_TYPES:\n",
    "        TP = stats[t][\"TP\"]; FP = stats[t][\"FP\"]; FN = stats[t][\"FN\"]\n",
    "        prec = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "        rec  = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "        f1 = 2*prec*rec/(prec+rec) if (prec+rec) > 0 else 0.0\n",
    "        f1s[t] = f1\n",
    "    macro_f1 = sum(f1s.values()) / len(f1s)\n",
    "    return macro_f1, f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f959cdd6-9fc3-4a78-b9ec-25f44d3accfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc78866a9164cffa8dce39ff951797b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2726 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m     y_pred_spans\u001b[38;5;241m.\u001b[39mappend(pred_spans)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Финальные метрики\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m macro_f1, per_type \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_entity_macro_f1\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true_spans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_spans\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMacro-F1:\u001b[39m\u001b[38;5;124m\"\u001b[39m, macro_f1)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-type F1:\u001b[39m\u001b[38;5;124m\"\u001b[39m, per_type)\n",
      "Cell \u001b[0;32mIn[14], line 45\u001b[0m, in \u001b[0;36mcompute_entity_macro_f1\u001b[0;34m(y_true_spans_list, y_pred_spans_list)\u001b[0m\n\u001b[1;32m     43\u001b[0m pred_by_type \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mset\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s,e,tag \u001b[38;5;129;01min\u001b[39;00m true_spans:\n\u001b[0;32m---> 45\u001b[0m     typ \u001b[38;5;241m=\u001b[39m \u001b[43mtag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     46\u001b[0m     true_by_type[typ]\u001b[38;5;241m.\u001b[39madd((s,e))\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s,e,tag \u001b[38;5;129;01min\u001b[39;00m pred_spans:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "y_true_spans = []\n",
    "y_pred_spans = []\n",
    "\n",
    "for i in tqdm(range(len(val_dataset))):\n",
    "    item = val_dataset[i]\n",
    "    text = item[\"text\"]\n",
    "\n",
    "    # Токенизация с возвратом offset_mapping\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_offsets_mapping=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Сохраняем смещения для постобработки\n",
    "    offsets_cpu = enc[\"offset_mapping\"][0].cpu().numpy().tolist()\n",
    "\n",
    "    # Убираем offset_mapping перед передачей в модель\n",
    "    enc = {k: v.to(device) for k, v in enc.items() if k != \"offset_mapping\"}\n",
    "\n",
    "    # Прогон через модель\n",
    "    with torch.inference_mode():\n",
    "        logits = model(**enc).logits  # (1, seq_len, num_labels)\n",
    "\n",
    "    preds = logits.argmax(dim=-1)[0].cpu().numpy().tolist()\n",
    "\n",
    "    # Преобразуем предсказания в spans\n",
    "    pred_spans = tokens_to_spans(preds, offsets_cpu)\n",
    "\n",
    "    # Ground truth (char spans) из val_ann\n",
    "    true_spans = val_ann[i]\n",
    "\n",
    "    y_true_spans.append(true_spans)\n",
    "    y_pred_spans.append(pred_spans)\n",
    "\n",
    "# Финальные метрики\n",
    "macro_f1, per_type = compute_entity_macro_f1(y_true_spans, y_pred_spans)\n",
    "print(\"Macro-F1:\", macro_f1)\n",
    "print(\"Per-type F1:\", per_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc5d749-168d-4b81-be70-9037d5a6d9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (x5_ner_env)",
   "language": "python",
   "name": "x5_ner_env"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
