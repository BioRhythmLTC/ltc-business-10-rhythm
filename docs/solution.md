# Solution Documentation

Краткое описание: сервис выделяет сущности `TYPE`, `BRAND`, `VOLUME`, `PERCENT` из коротких товарных описаний. Финальная модель — `rubert-base-cased (DeepPavlov)` с токенной классификацией в BIO-формате, Macro-F1 на валидации ≈0.92. Сервис реализован на FastAPI, поддерживает асинхронную обработку, микробатчинг и кэширование.

## 1. Технический стек

Языки: Python 3.10  
ML: PyTorch, HuggingFace Transformers  
Сервис: FastAPI, Uvicorn, Gunicorn  
Инфраструктура: Docker 
Инструменты производительности: asyncio, микробатчинг, TTL-кэш

## 2. Архитектура решения

### 2.1 Компоненты и взаимодействие

```
[Client]
   │  POST /api/predict
   ▼
[FastAPI]
   │
   ├─► [CacheManager] ── HIT ──► [Response]
   │
   └─► MISS ──► [MicroBatcher]
                    │
                    ▼
           [Semaphore → ThreadPool]
                    │
                    ▼
             [ModelManager]
      (HF tokenizer + torch model)
                    │
                    ▼
           [Postprocessing (BIO→spans)]
                    │
                    ▼
        [Cache set] ──► [Response]
```

Ключевые узлы  
FastAPI: асинхронные эндпоинты `/api/predict`, `/api/predict_batch`, `/health`  
ModelManager: загрузка артефактов, выбор `cpu/cuda`, функции `predict` и `predict_batch`  
MicroBatcher: короткое окно агрегации запросов, один батч инференса для нескольких клиентов  
CacheManager: потокобезопасный TTL-кэш по входным строкам  
Параллелизм: ограничения через семафор, оффлоад инференса в пул потоков

### 2.2 Сквозной путь запроса

```
Client
  │
  ▼
POST /api/predict {"input": "..."}
  │
  ▼
FastAPI handler (async)
  │
  ├─► Cache HIT ──► Response
  │
  └─► Cache MISS ──► Batch/Inference
                        │
                        ▼
                 ModelManager.predict
                        │
                        ▼
                Postprocessing & Cache
                        │
                        ▼
                    Response
```

## 3. Архитектура модели NER

```
[Входной текст]
        │
        ▼
 [Предобработка]
  нормализация: невидимые пробелы, нижний регистр, ё→е,
  разделение слитых границ (лат↔кир, число↔единица),
  исправление смешанных алфавитов, безопасные цифро-буквенные замены
        │
        ▼
 [Tokenizer (HuggingFace)]
        │
        ▼
 [Трансформер-энкодер (RuBERT-base-cased)]
        │
        ▼
 [Линейный слой токенной классификации]
        │
        ▼
 [BIO-предсказания по токенам]
        │
        ▼
 [Постобработка]
  склейка B/I в сущности, перенос в символьные спаны,
  нормализация единиц/процентов (value + unit; число)
        │
        ▼
[Выход: [{start_index, end_index, entity}]]
```

Формат классов: BIO для `TYPE`, `BRAND`, `VOLUME`, `PERCENT` плюс `O`

## 4. Данные и подготовка

Предобработка (одинаково для train/inference)  
Удаление невидимых символов, нижний регистр, замена ё→е  
Разделение слитых границ: латиница↔кириллица, число↔единица  
Выправление смешанных алфавитов внутри слова  
Безопасные цифро-буквенные замены: 0→o, 1→l, 3→e, 5→s

Разметка  
Перевод исходной разметки в символьные BIO  
Точное выравнивание к токенам по `offset_mapping`, спец-токены маскируются значением потерь −100

Постобработка  
Склейка соседних отрезков одной сущности  
Разметка по словам с корректными B-/I-префиксами для API  
Нормализация объёмов и процентов; поддержаны русские и английские формы единиц

## 5. Обучение

Задача: токенная классификация (BIO)  
Модель: `rubert-base-cased (DeepPavlov)`  
Гиперпараметры: 3 эпохи, `lr ≈ 2e-5`, длина входа 128 токенов  
Баланс классов: таргет-oversampling редких (`PERCENT`, умеренно `VOLUME/BRAND`)  
Выбор чекпоинта: лучший по span-level Macro-F1 на валидации  
Итог: Macro-F1 ≈ 0.93 в нашем валидационном пайплайне  
Стабильность: идентичные функции нормализации/выравнивания в train и inference

Сравнение моделей  
`mdeberta-v3-base`: выше точность, но не проходит SLO по задержке  
`rubert-tiny`: минимальная задержка, но заметное падение качества  
`rubert-base-cased`: компромисс скорость/качество, выбран как финальный

## 6. Инференс и производительность

Асинхронность: FastAPI хендлеры не блокируют цикл событий  
Оффлоад: инференс в `ThreadPool`, параллелизм ограничен семафором  
Микробатчинг: короткое окно агрегации повышает пропускную способность  
Кэширование: TTL-кэш по входным строкам снижает латентность повторов  
Параметры тюнинга окружения: числа воркеров Gunicorn, размер батча, лимиты потоков BLAS/torch

## 7. API

Эндпоинты  
`POST /api/predict` — одна строка  
`POST /api/predict_batch` — список строк  
`GET /health` — проверка готовности  
`POST /warmup` — прогрев модели (опционально)  
`GET /cache/stats`, `DELETE /cache/clear`, `GET /cache/info` — управление кэшем (опционально)

Примеры

```
POST /api/predict
Body: {"input": "cola 500ml 5%"}
Response: [
  {"start_index": 0, "end_index": 4, "entity": "B-BRAND"},
  {"start_index": 5, "end_index": 10, "entity": "B-VOLUME"},
  {"start_index": 11, "end_index": 13, "entity": "B-PERCENT"}
]
```

```
POST /api/predict_batch
Body: {"inputs": ["cola 500ml", "фанта 1л 6%"]}

Response: [
  [
    {"start_index":0,"end_index":4,"entity":"B-BRAND"},
    {"start_index":5,"end_index":10,"entity":"B-VOLUME"}
  ],
  [
    {"start_index":0,"end_index":5,"entity":"B-BRAND"},
    {"start_index":6,"end_index":7,"entity":"B-VOLUME"},
    {"start_index":8,"end_index":10,"entity":"B-PERCENT"}
  ]
]

Схема ошибок  
422 — некорректный ввод  
500 — внутренняя ошибка инференса

## 8. Развертывание

Контейнер  
Dockerfile включает установку модели и артефактов, healthcheck

Запуск  
Gunicorn с `uvicorn.workers.UvicornWorker`, несколько воркеров на узел  
Переменные окружения для тюнинга параллелизма, батчинга, путей к артефактам

Безопасность и CORS  
По умолчанию используется `CORSMiddleware` с `allow_origins=["*"]`. Рекомендуется ограничить список доменов в продакшене.


## 9. Качество, ошибки и устойчивость к шуму

Учёт опечаток и неполных слов  
Нормализация смешанных алфавитов, слитных единиц, цифро-буквенных замен  
Склейка спанов и нарезка по словам восстанавливают цельные сущности

Типовые сложности и решения  
Редкие классы → oversampling и контроль Macro-F1  
BIO-границы и доминирование класса O → нормализация до токенизации и точное выравнивание  
Шум форматов единиц/процентов → канонизация и пост-правила

Ограничения  
Контекст ограничен 128 токенами  
Крайние сокращения и экзотические единицы могут требовать дообучения

## 10. Воспроизводимость обучения

Подготовка данных  
Единые функции предобработки и выравнивания к токенам

Процесс  
Запуск обучения с фиксированными гиперпараметрами  
Отбор чекпоинта по Macro-F1 на валидации  
Сохранение артефактов токенайзера и модели

Вывод артефактов  
Папка модели содержит веса, конфиг, словарь токенайзера и таблицу метрик

## 11. Конфигурация

Ключевые параметры окружения  
`ARTIFACTS_DIR` — путь к артефактам модели  
`X5_FORCE_DEVICE` или `FORCE_DEVICE` — выбор устройства (`cpu`/`cuda`/`mps`, если доступно)  
`PREDICT_MAX_CONCURRENCY` — лимит параллельных инференсов на процесс  
`MICRO_BATCH_ENABLED` — включить микробатчинг (`true/false`)  
`MICRO_BATCH_MAX_SIZE`, `MICRO_BATCH_MAX_WAIT_MS`, `MICRO_BATCH_HARD_TIMEOUT_MS` — тюнинг микробатчинга  
`CACHE_MAX_SIZE`, `CACHE_TTL_SECONDS`, `CACHE_ENABLED` — параметры кэша  
`TOKENIZERS_PARALLELISM=false`, `OMP_NUM_THREADS`, `MKL_NUM_THREADS`, `TORCH_NUM_THREADS`, `TORCH_NUM_INTEROP_THREADS` — тюнинг потоков  
Примечание: `MAX_SEQ_LEN` фиксирована в коде (128).

## 13. Структура репозитория

```
.
├── service/
│   ├── main.py           # FastAPI, маршруты, lifespan, микробатчинг
│   ├── managers.py       # ModelManager, CacheManager
│   ├── models.py         # Pydantic-схемы
│   ├── config.py         # Конфигурация и константы
│   └── utils.py          # Пред/пост-обработка, декодирование, метрики
├── scripts/
│   ├── run_gunicorn.sh
│   └── evaluate_service.py
├── artifacts/            # артефакты финальной модели
├── docker/               # Dockerfile (может быть в корне)
├── README.md
└── docs/
    └── solution.md
```

## 14. Будущие улучшения

Обогащение данными: синтетика редких классов и редких единиц  
Семплинг по трудным примерам и активное обучение  
Лёгкая архитектура с дистилляцией для снижения латентности  
Расширение нормализатора единиц и покрытие редких форматов

## 15. Контакты

BioRhythm, телеграм @MarinTsv
